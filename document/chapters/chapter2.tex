\chapter{Systematic Literature Review}

\label{chapter:systematic_review}

\newcommand{\RQI}{What are the main artificial intelligence and machine learning technologies related to voice user interfaces, specially in Speech Recognition, Speech Synthesis, Natural Language Processing, and Trigger-word detection?}

\newcommand{\RQII}{What is the state-of-the-art and the main services that exist in the market on Voice User Interfaces?}

\newcommand{\RQIII}{How does one implement a Voice User Assistants(VUIs) for domain-specific contexts?}

The development of artificial intelligence technologies in recent times is undeniable. Therefore, it is expected that research and screening of documents that represent this knowledge obtained can lead us to understand how voice assistants work and how to implement a possible template that is capable of receiving different domains/contexts and training the platform to be able to execute commands. in these respective domains, especially, in our case, in human resources.

\section{Research Methodology}

This section explains the strategy by which our research was carried out, including the questions that were defined, the sources used, the search terms, and the inclusion and exclusion criteria. At the end, we present a small summary of what this process was like.

\subsection{Research Questions}

The general objective of our literature review is to understand how voice assistants trained for specific domain contexts work. To be able to answer this question, it is necessary to divide it into others, which will be able to offer a general picture of the current state of the art, and how a solution should be designed. The questions defined in our research are found in table 2.

\begin{tabularx}{0.8\textwidth} {
    | >{\raggedright\arraybackslash}X 
    | >{\centering\arraybackslash}X 
    | >{\raggedleft\arraybackslash}X |}
    \hline
    item 11 & item 12 & item 13 \\
    \hline
    item 21  & item 22  & item 23  \\
    \hline
\end{tabularx}

\begin{table}[h!]
    \centering
    \begin{tabular}{| c | c | c |} 
        \hline
        Research Question ID & Research Question & Research Question Domain \\  
        \hline
        RQ1 & \RQI & e \\
        \hline
        RQ2 & \RQII & e \\
        \hline
        RQ3 & \RQIII & e \\ 
        \hline
    \end{tabular}
    \caption{Research questions}
    \label{table:2}
\end{table}

\subsection{Research Terms}

\subsection{Inclusion and Exclusion Criteria}

\subsection{Data Extraction}

\section{Search Results}

\subsection{\RQI}

\citet{Li20193784} proposes a name-free domain classification that can continuous learn and adapt the model to incoming domains without the need of retraining. \citet{He202003654} defines the DeBERTa pre-trained language model, that can be fine-tuned in a number of Natural Language Processing(NLP) downstream tasks.

SLURP \cite{slurp} is an audio and human annotation dataset which the main purpose is to train spoken language understanding, but that it can be also used in other Natural Language Processing tasks, that is highly bigger than other default datasets in NLP, containing almost 72k audio recordings, of single turn interactions with a home assistants, mapping 3 semantics levels: Scenario, action and entities, with a scope of 18 domains, 46 defined actions and 55 entities types. It main advantage is to be able to train different NLP models, with different architectures, for comparison purposes, specially in terms of memory and computational resources.

\subsection{\RQII}

In \cite{Hoy201881} the main voice user assistants in the market are Amazon's Alexa, Microsoft's Cortana, Google's Google Assistant, and Apple's Siri. These assistants have mostly common features that includes be able to search for content in the internet, help the user organize its life by setting reminders, tasks or calendar events, and it can be integrate with third-party application to execute commands related to them, like request a trip on Uber, or a food order in a food delivery application, and also control IoT devices like TVs, thermostats, door locks, etc. These services are usually executed through brand-specific smart devices, like Amazon's Echo, and Google's Home.

Those software platforms have issues related to security and privacy. Those devices cannot yet authenticate their users by voice, and considering their privileges, they can be a huge threat. Also, it was comproved that those devices are capable of recognizing ultrasonic frequencies and execute accordingly. Also, many users feel afraid that their data is being constantly recording and being sent to private data centers.

\subsection{\RQIII}

\citet{Li20193784} implemented a name-free domain classification model capable of using personalized information to support the classification of an utterance in a domain. The model’s name is CoNDA, and it is baselined on SHORLISTER. Besides its name-free feature, CoNDA supports domain adaptation, by continuous learning the new domains without the need to retrain the whole model. Just like its baseline model, CoNDA contains three modules: The first is a LSTM encoder that converts utterances in dense vector representation by using word embeddings. The second model is the personalized domain summarization, which outputs an enabled personalized domain dense vector. and finally the third module, which is a two-layer feed forward network that will act as our classifier. In their experimentation, the model results in a 95.6\% prediction accuracy for the initial trained models, and 88.2\% accuracy after we feed the model 100 new domains, which is only 3.6% lower than the upper bound model, which is retraining it with the concatenated dataset of all the previous model.

In \citet{He202003654}, The Decoding-enhanced BERT with disentangled attention, DeBERTa, is a pre-trained language model, based on BERT, from Google, which adds two main new techniques: A disentangled attention mechanism, and a enhanced mask decoder. The disentangled attention mechanism consider two vectors representing its word embeddings, for content, and for position, instead of a concatenated vector like in BERT, and the attention weights are measured as disentangled matrices computed by its these vectors in position and content . The enhanced mask decoder, used in masked language modeling, is very similar to BERT’s one, but its absolute position mask decoder is used before the soft-max layer processing. To prove the efficiency of both techniques in DeBERTa, the model was trained in half the data necessary for the BERT model, and achieved a 0.9\% increase in MNLI, on SQuAD v2.0 by 2.3\%, and RACE by 3.6\%.

\section{Search Conclusions}

\subsection{\RQI}

todo

\subsection{\RQII}

todo

\subsection{\RQIII}

todo

\section{Additional Resolutions}




